{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import os\n",
    "from google.cloud import storage\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@click.command() # click commands instead of argparse.ArgumentParser()... or sys.argv[n]\n",
    "#@click.option('--sa_path', help='Path to the service account json file')\n",
    "#@click.option('--project_id', help='Project ID of you GCP project')\n",
    "#@click.option('--year', default=2021, help='Year to download')\n",
    "#@click.option('--bucket', help='Name of the bucket to upload the data')\n",
    "#@click.option('--color', help='Str of the taxi-color for which data should be extracted')\n",
    "#@click.option('--month', help='Int of the month to summarize the data for')\n",
    "\n",
    "sa_path = '../mle-neue-fische-gunnaroeh-0fc41b31bc57.json'\n",
    "project_id = 'mle-neue-fische-gunnaroeh'\n",
    "bucket = \"01_data_pipeline_project\" \n",
    "project_id = \"mle-neue-fische-gunnaroeh\" \n",
    "color = \"green\"\n",
    "year = 2021\n",
    "month = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. E: Extract the data as a function\n",
    "def extract_data(sa_path, bucket, color, year, month):\n",
    "    # Spark Session\n",
    "    spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(f\"Pipe-{color}_taxi_{year}-{month:02d}\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "    # string of the file to be loaded\n",
    "    file_name = f\"ny_taxi/{color}_tripdata_{year}-{month:02d}.parquet\"\n",
    "    \n",
    "    # Establish connection to GCS-Bucket\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = sa_path\n",
    "    # Create an instance of the GCS client to communicate with the Cloud\n",
    "    client = storage.Client()\n",
    "    \n",
    "    # Retrieve address/path to the specified bucket and a blob representing the table\n",
    "    bucket = client.get_bucket(bucket)\n",
    "    blob = bucket.get_blob(file_name)\n",
    "\n",
    "    # Download parquet and write it to memory as binary to be accessible\n",
    "    pq_taxi = blob.download_as_bytes()    \n",
    "    pq_taxi = BytesIO(pq_taxi)\n",
    "    \n",
    "    # read the object in memory\n",
    "    df_taxi = spark.read.parquet(pq_taxi)\n",
    "    return df_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = extract_data(sa_path, bucket, color, year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
